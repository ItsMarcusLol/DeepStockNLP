{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize_sentiment(tweet):\n",
    "    analysis = TextBlob((str(tweet)))\n",
    "    return analysis.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the path for the CSV and put it in here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news = pd.read_csv(r'C:/Users/dcard/Cap-Repo/DeepStockNLP/Data/18-20-csv/2018-2021-input-2-22-21.csv')\n",
    "news = pd.read_csv(r'C:/Users/dcard/Cap-Repo/DeepStockNLP/Data/18-20-csv/2018-2021-input-2-22-21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train news and test news datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_news(day, month, year, data):\n",
    "    index = 0\n",
    "    dataset = []\n",
    "    d1 = datetime(year, month, day).date() \n",
    "    for date in data['Date']:\n",
    "        d = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "        if d1 > d:\n",
    "            dataset.append(data.iloc[index])\n",
    "        index = index +1\n",
    "        df = pd.DataFrame(dataset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_news(day, month, year,data):\n",
    "    index = 0\n",
    "    dataset = []\n",
    "    d1 = datetime(year, month, day).date() \n",
    "    for date in data['Date']:\n",
    "        d = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "        if d1 < d:\n",
    "            dataset.append(data.iloc[index])\n",
    "        index = index +1\n",
    "        df = pd.DataFrame(dataset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Enter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-13 2020-03-12\n"
     ]
    }
   ],
   "source": [
    "num_column = (len(news.columns))\n",
    "# day, month, year\n",
    "\n",
    "train_date = news['Date'][(int(len(news) * .7))]\n",
    "year = train_date[0:4]\n",
    "month = train_date[5:7]\n",
    "day = train_date[8:10]\n",
    "\n",
    "test_date =  news['Date'][(int(len(news) * .7)-1)]\n",
    " \n",
    "tst_day =  test_date[8:10]\n",
    "tst_month = test_date[5:7]\n",
    "tst_year =test_date[0:4]\n",
    "\n",
    "print(train_date, test_date)\n",
    "\n",
    "train_news = get_train_news(int(day), int(month), int(year), news)\n",
    "test_news = get_test_news(int(tst_day), int(tst_month), int(tst_year), news)\n",
    "# train_news = get_train_news(5, 3, 2020, news)\n",
    "# test_news = get_test_news(4, 3, 2020, news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_list = []\n",
    "for row in range (0, len(train_news.index)):\n",
    "    train_news_list.append(' '.join(str(k) for k in train_news.iloc[row,12:num_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectorize = CountVectorizer(min_df=0.01, max_df=0.8)\n",
    "news_vector = vectorize.fit_transform(train_news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TABLE OF FREQUENCY WORD DISTRIBUTION (552, 325)\n"
     ]
    }
   ],
   "source": [
    "print(\"THE TABLE OF FREQUENCY WORD DISTRIBUTION\", news_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1953,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(news_vector, train_news[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1954,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news_list = []\n",
    "for row in range(0, len(test_news.index)):\n",
    "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:num_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1955,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = vectorize.transform(test_news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "Actual           \n",
       "0          30  72\n",
       "1          36  99"
      ]
     },
     "execution_count": 1956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_vector)\n",
    "pd.crosstab(test_news[\"Label\"], predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1957,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the baseline model accuracy 0.5443037974683544\n"
     ]
    }
   ],
   "source": [
    "accuracy1=accuracy_score(test_news[\"Label\"], predictions)\n",
    "print(\"the baseline model accuracy\", accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words according to the baseline model           Word  Coefficient\n",
      "65      change     1.570137\n",
      "221    project     1.059030\n",
      "83     digital     0.940982\n",
      "278     things     0.903217\n",
      "319      years     0.873990\n",
      "192        now     0.810492\n",
      "147      intel     0.789582\n",
      "265     stocks     0.784403\n",
      "138       high     0.774204\n",
      "153  investors     0.768039\n",
      "Last ten words according to the baseline model        Word  Coefficient\n",
      "144  huawei    -0.821939\n",
      "166     llc    -0.830096\n",
      "117    fund    -0.841443\n",
      "256   sinks    -0.845750\n",
      "255   since    -0.870145\n",
      "137    here    -0.883337\n",
      "41      big    -0.900161\n",
      "312     who    -0.943832\n",
      "156     its    -1.024911\n",
      "286   trade    -1.103275\n"
     ]
    }
   ],
   "source": [
    "words = vectorize.get_feature_names()\n",
    "coefficients = model.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : words, 'Coefficient' : coefficients})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0,1])\n",
    "print(\"Top ten words according to the baseline model\", coeffdf.head(10))\n",
    "print(\"Last ten words according to the baseline model\", coeffdf.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest with tfid and bigram 0.5738396624472574\n"
     ]
    }
   ],
   "source": [
    "nvectorize = TfidfVectorizer(min_df=0.01, max_df=0.95, ngram_range=(2,2))\n",
    "news_nvector = nvectorize.fit_transform(train_news_list)\n",
    "\n",
    "rfmodel = RandomForestClassifier(random_state = 100, criterion='entropy', max_depth=None, n_estimators=125)\n",
    "rfmodel = rfmodel.fit(news_nvector, train_news[\"Label\"])\n",
    "test_news_list = []\n",
    "for row in range(0, len(test_news.index)):\n",
    "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:num_column]))\n",
    "ntest_vector = nvectorize.transform(test_news_list)\n",
    "\n",
    "rfpredictions = rfmodel.predict(ntest_vector)\n",
    "accuracyrf = accuracy_score(test_news[\"Label\"], rfpredictions)\n",
    "print(\"Random forest with tfid and bigram\", accuracyrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost/Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     top1  top2  top3  top4  top5  top6  top7  top8  top9  top10  ...  top30  \\\n",
      "0    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "1    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "2    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "3    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "4    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
      "547  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "548  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "549  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "550  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "551  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "\n",
      "     top31  top32  top33  top34  top35  top36  top37  top38  top39  \n",
      "0     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "1     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "2     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "3     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "4     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "547   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "548   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "549   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "550   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "551   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "\n",
      "[552 rows x 39 columns]\n",
      "[21:46:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcard\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_sentiment = copy.deepcopy(train_news)\n",
    "test_sentiment = copy.deepcopy(test_news)\n",
    "train_news2 = copy.deepcopy(train_news)\n",
    "test_news2 = copy.deepcopy(test_news)\n",
    "\n",
    "train_sentiment = train_sentiment.drop(['Date', 'Label', '1', '2', '3', '4', '5', '6', '7', '8', '9','10'], axis=1)\n",
    "for column in train_sentiment:\n",
    "    train_sentiment[column] = train_sentiment[column].apply(analize_sentiment)\n",
    "    train_news2[column] = train_sentiment[column] + 10\n",
    "train_sentiment = train_sentiment + 10\n",
    "print(train_sentiment)\n",
    "test_sentiment = test_sentiment.drop(['Date', 'Label', '1', '2', '3', '4', '5', '6', '7', '8', '9','10'], axis=1)\n",
    "for column in test_sentiment:\n",
    "    test_sentiment[column] = test_sentiment[column].apply(analize_sentiment)\n",
    "    test_news2[column] = test_sentiment[column] + 10  \n",
    "test_sentiment = test_sentiment + 10\n",
    "\n",
    "XGB_model = XGBClassifier(random_state=100)\n",
    "gradiant = XGB_model.fit(train_sentiment, train_news['Label'])\n",
    "y_pred = gradiant.predict(test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20  82]\n",
      " [ 32 103]]\n",
      "Sentiment Accuracy 0.5189873417721519\n",
      "f1_score 0.4784799852046687\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_news['Label'], y_pred))\n",
    "print(\"Sentiment Accuracy\", accuracy_score(test_news['Label'], y_pred))\n",
    "print(\"f1_score\", f1_score(test_news['Label'], y_pred, average='weighted'))\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - includes trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1985,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Date' 'Label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1985-ca9d83fea50a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_news2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_news2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_news2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_news2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mXGB_model2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgradiant2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGB_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_news2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_news\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Date' 'Label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_news2 = train_news2.drop(['Date','Label'], axis = 1)\n",
    "test_news2 = test_news2.drop(['Date', 'Label'], axis = 1)\n",
    "\n",
    "XGB_model2 = XGBClassifier()\n",
    "gradiant2 = XGB_model2.fit(train_news2, train_news['Label'])\n",
    "y_pred2 = gradiant2.predict(test_news2)\n",
    "\n",
    "\n",
    "# print(confusion_matrix(test_news['Label'], y_pred))\n",
    "print(\"Sentiment Accuracy with Trend\", accuracy_score(test_news['Label'], y_pred2))\n",
    "print(\"f1_score\", f1_score(test_news['Label'], y_pred2, average='weighted'))\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted XGBoost (attempted to put weight towards headlines) Vanessa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "train_sentiment_weight = train_news\n",
    "test_sentiment_weight = test_news\n",
    "weighted_data=[]\n",
    "empty_data=[]\n",
    "\n",
    "train_sentiment_weight = train_sentiment_weight.drop(['Date', 'Label'], axis=1)\n",
    "for column in train_sentiment_weight:\n",
    "    train_sentiment_weight[column] = train_sentiment_weight[column].apply(analize_sentiment)\n",
    "train_sentiment_weight = train_sentiment_weight + 10\n",
    "\n",
    "test_sentiment_weight = test_sentiment_weight.drop(['Date', 'Label'], axis=1)\n",
    "for column in test_sentiment_weight:\n",
    "    test_sentiment_weight[column] = test_sentiment_weight[column].apply(analize_sentiment)\n",
    "test_sentiment_weight = test_sentiment_weight + 10\n",
    "\n",
    "for column in train_news:\n",
    "    if not train_news[column].empty:\n",
    "        empty_data = train_news[column]\n",
    "    else:\n",
    "        weighted_data = train_news[column]\n",
    "\n",
    "weighted_XGB = XGBClassifier()\n",
    "weighted_XGB.fit(train_sentiment_weight, train_news['Label'], sample_weight=weighted_data)\n",
    "y_pred_weight = weighted_XGB.predict(test_sentiment_weight, ntree_limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Accuracy 0.5189873417721519\n",
      "F1 weighted 0.4784799852046687\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Accuracy\", accuracy_score(test_news['Label'], y_pred_weight))\n",
    "print(\"F1 weighted\", f1_score(test_news['Label'], y_pred_weight, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted attempt 2 (Vans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1990,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  top1 top2 top3 top4 top5  \\\n",
      "0                                                  NaN  NaN  NaN  NaN  NaN   \n",
      "1                                                  NaN  NaN  NaN  NaN  NaN   \n",
      "2                                                  NaN  NaN  NaN  NaN  NaN   \n",
      "3             sharing online albums with google photos  NaN  NaN  NaN  NaN   \n",
      "4    google memo author sues, claiming bias against...  NaN  NaN  NaN  NaN   \n",
      "..                                                 ...  ...  ...  ...  ...   \n",
      "547                                                NaN  NaN  NaN  NaN  NaN   \n",
      "548                                                NaN  NaN  NaN  NaN  NaN   \n",
      "549  you canâ€™t fight city hall. but maybe you can f...  NaN  NaN  NaN  NaN   \n",
      "550                                                NaN  NaN  NaN  NaN  NaN   \n",
      "551                                                NaN  NaN  NaN  NaN  NaN   \n",
      "\n",
      "    top6 top7 top8 top9 top10  ... top30 top31 top32 top33 top34 top35 top36  \\\n",
      "0    NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1    NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2    NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3    NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4    NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "..   ...  ...  ...  ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "547  NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "548  NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "549  NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "550  NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "551  NaN  NaN  NaN  NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "    top37 top38 top39  \n",
      "0     NaN   NaN   NaN  \n",
      "1     NaN   NaN   NaN  \n",
      "2     NaN   NaN   NaN  \n",
      "3     NaN   NaN   NaN  \n",
      "4     NaN   NaN   NaN  \n",
      "..    ...   ...   ...  \n",
      "547   NaN   NaN   NaN  \n",
      "548   NaN   NaN   NaN  \n",
      "549   NaN   NaN   NaN  \n",
      "550   NaN   NaN   NaN  \n",
      "551   NaN   NaN   NaN  \n",
      "\n",
      "[552 rows x 39 columns]\n",
      "     top1  top2  top3  top4  top5  top6  top7  top8  top9  top10  ...  top30  \\\n",
      "0    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "1    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "2    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "3    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "4    10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n",
      "547  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "548  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "549  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "550  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "551  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   10.0  ...   10.0   \n",
      "\n",
      "     top31  top32  top33  top34  top35  top36  top37  top38  top39  \n",
      "0     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "1     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "2     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "3     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "4     10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "547   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "548   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "549   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "550   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "551   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0   10.0  \n",
      "\n",
      "[552 rows x 39 columns]\n",
      "[21:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcard\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_sentiment_weight = train_news\n",
    "test_sentiment_weight = test_news\n",
    "weighted_data=[]\n",
    "empty_data=[]\n",
    "\n",
    "train_sentiment_weight = train_sentiment_weight.drop(['Date', 'Label'], axis=1)\n",
    "print(train_sentiment_weight)\n",
    "for column in train_sentiment_weight:\n",
    "    train_sentiment_weight[column] = train_sentiment_weight[column].apply(analize_sentiment)\n",
    "train_sentiment_weight = train_sentiment_weight + 10\n",
    "print(train_sentiment_weight)\n",
    "test_sentiment_weight = test_sentiment_weight.drop(['Date', 'Label'], axis=1)\n",
    "for column in test_sentiment_weight:\n",
    "    test_sentiment_weight[column] = test_sentiment_weight[column].apply(analize_sentiment)\n",
    "test_sentiment_weight = test_sentiment_weight + 10\n",
    "\n",
    "for column in train_news:\n",
    "    if not train_news[column].empty:\n",
    "        empty_data = train_news[column]\n",
    "    else:\n",
    "        weighted_data = train_news[column]\n",
    "\n",
    "weighted_XGB1 = XGBClassifier(scale_pos_weight = 60)\n",
    "weighted_XGB1.fit(train_sentiment_weight, train_news['Label'], sample_weight = weighted_data)\n",
    "y_pred_weight1 = weighted_XGB1.predict(test_sentiment_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Accuracy 0.5569620253164557\n",
      "F1 weighted 0.4671052917921004\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Accuracy\", accuracy_score(test_news['Label'], y_pred_weight1))\n",
    "print(\"F1 weighted\", f1_score(test_news['Label'], y_pred_weight1, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted - using trends (Erika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1967,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_weight(train_sentiment):\n",
    "    train_weight = []\n",
    "\n",
    "    for across in range(len(train_sentiment)):\n",
    "        for i in range(500):\n",
    "            train_weight.append(0.5)\n",
    "        for x in train_sentiment:\n",
    "            if x not in ['Date', 'Label', '1', '2','3','4','5','6','7','8','9', '10'] :\n",
    "                if train_sentiment[x][across] == 10.0:\n",
    "                    train_weight.append(0.5)\n",
    "                else:\n",
    "                    train_weight.append(0.8)\n",
    "    return train_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_weight(train_sentiment, test_sentiment):\n",
    "\n",
    "    test_weight = []\n",
    "    j = len(train_sentiment)\n",
    "    for across in range(len(test_sentiment)):\n",
    "        for i in range(500):\n",
    "            test_weight.append(0.5)\n",
    "        for x in test_sentiment:\n",
    "            if x not in ['Date', 'Label', '1', '2','3','4','5','6','7','8','9', '10'] :\n",
    "                if test_sentiment[x][j] == 10.0:\n",
    "                    test_weight.append(0.5)\n",
    "                else:\n",
    "                    test_weight.append(0.8)\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Sentiment Accuracy with Trend with weight 0.45569620253164556\n",
      "f1_score 0.4550178215858112\n"
     ]
    }
   ],
   "source": [
    "train_weight = get_train_weight(train_sentiment)\n",
    "test_weight = get_test_weight(train_sentiment, test_sentiment)\n",
    "\n",
    "XGB_model4 = XGBClassifier()\n",
    "\n",
    "num_round = 2\n",
    "param = {'max_depth' : 2, 'eta': 1, 'objective':'binary:logistic' }\n",
    "gradiant4 = XGB_model4.fit(train_news2, train_news['Label'])\n",
    "y_pred4 = gradiant4.predict(test_news2)\n",
    "\n",
    "print(\"Sentiment Accuracy with Trend with weight\", accuracy_score(test_news['Label'], y_pred4))\n",
    "print(\"f1_score\", f1_score(test_news['Label'], y_pred4, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Weighted Accuracy 2 0.5189873417721519\n",
      "F1 weighted 0.4784799852046687\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment Weighted Accuracy 2\", accuracy_score(test_news['Label'], y_pred_weight))\n",
    "print(\"F1 weighted\", f1_score(test_news['Label'], y_pred_weight, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual model for prices and headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Sentiment Accuracy with Trend with weight 0.5189873417721519\n",
      "f1_score 0.5186961718821834\n"
     ]
    }
   ],
   "source": [
    "head_cols = train_sentiment.columns\n",
    "\n",
    "price_train = train_news.drop(head_cols, axis = 1)\n",
    "price_train = price_train.drop(['Date', 'Label'], axis =1)\n",
    "\n",
    "price_test = test_news.drop(head_cols, axis = 1)\n",
    "price_test = price_test.drop(['Date', 'Label'], axis =1)\n",
    "\n",
    "dtrain = xgb.DMatrix( data = price_train, label = train_news['Label'])\n",
    "dtest = xgb.DMatrix(data = price_test, label = test_news['Label'])\n",
    "params  = dict(max_depth=2, eta=1, verbose=0, nthread=2, eval_metric = \"auc\",\n",
    "              objective=\"binary:logistic\")\n",
    "\n",
    "m = xgb.train(params, dtrain)\n",
    "\n",
    "y_price = m.predict(dtest)\n",
    "\n",
    "i = 0\n",
    "y = []\n",
    "for p in y_price:\n",
    "    if p > 0.49:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "    i = i + 1\n",
    "print(\"Sentiment Accuracy with Trend with weight\", accuracy_score(test_news['Label'], y))\n",
    "print(\"f1_score\", f1_score(test_news['Label'], y, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Sentiment Accuracy with Trend with weight 0.5189873417721519\n",
      "f1_score 0.4724894514767933\n"
     ]
    }
   ],
   "source": [
    "head_cols = train_sentiment.columns\n",
    "\n",
    "head_train = copy.deepcopy(train_sentiment)\n",
    "\n",
    "head_test = copy.deepcopy(test_sentiment)\n",
    "\n",
    "dtrain2 = xgb.DMatrix( data = head_train, label = train_news['Label'])\n",
    "dtest2 = xgb.DMatrix(data = head_test, label = test_news['Label'])\n",
    "params2  = dict(max_depth=2, eta=1, verbose=0, nthread=2, eval_metric = \"auc\",\n",
    "              objective=\"binary:logistic\")\n",
    "\n",
    "m = xgb.train(params2, dtrain2)\n",
    "\n",
    "y_head = m.predict(dtest2)\n",
    "\n",
    "i = 0\n",
    "y_h = []\n",
    "for p in y_head:\n",
    "    if p > 0.49:\n",
    "        y_h.append(1)\n",
    "    else:\n",
    "        y_h.append(0)\n",
    "    i = i + 1\n",
    "print(\"Sentiment Accuracy with Trend with weight\", accuracy_score(test_news['Label'], y_h))\n",
    "print(\"f1_score\", f1_score(test_news['Label'], y_h, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_price = pd.DataFrame(y_price, columns = [\"Price\"])\n",
    "df_head = pd.DataFrame(y_head, columns = [\"Head\"])\n",
    "\n",
    "date = test_news.drop(['1','2','3','4','5','6','7','8','9','10'], axis = 1)\n",
    "date = date.drop(test_sentiment.columns, axis = 1)\n",
    "date.index = np.arange(0, len(date))\n",
    "\n",
    "\n",
    "df_date = pd.DataFrame(date, columns = [\"Date\", \"Label\"])\n",
    "df1 = df_date.join(df_price)\n",
    "df2= df1.join(df_head)\n",
    "\n",
    "train_date = df2['Date'][(int(len(df2) * .7))]\n",
    "year = train_date[0:4]\n",
    "month = train_date[5:7]\n",
    "day = train_date[8:10]\n",
    "\n",
    "test_date =  df2['Date'][(int(len(df2) * .7)-1)]\n",
    " \n",
    "tst_day =  test_date[8:10]\n",
    "tst_month = test_date[5:7]\n",
    "tst_year =test_date[0:4]\n",
    "\n",
    "#day, month year\n",
    "train_d = get_train_news(int(day), int(month) , int(year), df2)\n",
    "\n",
    "test_d = get_test_news(int(tst_day), int(tst_month), int(tst_year), df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1974,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0.3878629  0.5770088  0.5804823  0.5804823  0.7619662  0.45087573\n",
      " 0.5770088  0.7619662  0.9209365  0.5120114  0.5770088  0.3878629\n",
      " 0.5120114  0.6217818  0.5804823  0.3878629  0.45087573 0.45087573\n",
      " 0.3878629  0.9234296  0.5120114  0.5770088  0.45087573 0.45087573\n",
      " 0.8396071  0.5725968  0.25058413 0.83441526 0.9209365  0.9640743\n",
      " 0.5770088  0.2652386  0.9234296  0.7001236  0.9234296  0.45087573\n",
      " 0.7619662  0.40177742 0.5194771  0.5770088  0.5804823  0.5725968\n",
      " 0.7619662  0.5770088  0.5770088  0.83441526 0.5120114  0.3878629\n",
      " 0.7619662  0.40177742 0.5770088  0.72711235 0.5804823  0.5770088\n",
      " 0.5804823  0.6309701  0.40177742 0.5120114  0.72711235 0.5770088\n",
      " 0.1569075  0.7619662  0.266403   0.5804823  0.585047   0.45087573\n",
      " 0.72711235 0.9181205  0.11454616 0.5770088  0.5120114  0.8396071 ]\n",
      "Sentiment Accuracy with Trend with weight 0.5138888888888888\n",
      "f1_score 0.49021364818328766\n"
     ]
    }
   ],
   "source": [
    "# print(price_train)\n",
    "w = [0.10, 0.90]\n",
    "tr_d = train_d.drop(['Date', 'Label'], axis = 1)\n",
    "tst_d = test_d.drop(['Date', 'Label'], axis =1)\n",
    "\n",
    "dtrain3 = xgb.DMatrix( data = tr_d, label = train_d['Label'], feature_names = ['Price', 'Head'])\n",
    "\n",
    "dtrain3.set_info(feature_weights = w)\n",
    "\n",
    "dtest3 = xgb.DMatrix(data = tst_d, label = test_d['Label'],  feature_names = ['Price', 'Head'])\n",
    "\n",
    "dtest3.set_info(feature_weights = w)\n",
    "\n",
    "params3  = dict(max_depth=2, eta=1, verbose=0, nthread=2, eval_metric = \"auc\",\n",
    "              objective=\"binary:logistic\")\n",
    "m1 = xgb.train(params3, dtrain3)\n",
    "\n",
    "y_final = m1.predict(dtest3)\n",
    "print(y_final)\n",
    "i = 0\n",
    "y_new = []\n",
    "for p in y_final:\n",
    "    if p > 0.49:\n",
    "        y_new.append(1)\n",
    "    else:\n",
    "        y_new.append(0)\n",
    "    i = i + 1\n",
    "\n",
    "# print(test_d['Label'])\n",
    "print(\"Sentiment Accuracy with Trend with weight\", accuracy_score(test_d['Label'], y_new))\n",
    "print(\"f1_score\", f1_score(test_d['Label'], y_new, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1975,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the testing data\n",
    "dtest3.save_binary('dtest.buffer')\n",
    "#dump model to txt\n",
    "m1.dump_model('dump.raw.txt')\n",
    "#save model \n",
    "m1.save_model('dump.raw.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[0.3878629  0.5770088  0.5804823  0.5804823  0.7619662  0.45087573\n",
      " 0.5770088  0.7619662  0.9209365  0.5120114  0.5770088  0.3878629\n",
      " 0.5120114  0.6217818  0.5804823  0.3878629  0.45087573 0.45087573\n",
      " 0.3878629  0.9234296  0.5120114  0.5770088  0.45087573 0.45087573\n",
      " 0.8396071  0.5725968  0.25058413 0.83441526 0.9209365  0.9640743\n",
      " 0.5770088  0.2652386  0.9234296  0.7001236  0.9234296  0.45087573\n",
      " 0.7619662  0.40177742 0.5194771  0.5770088  0.5804823  0.5725968\n",
      " 0.7619662  0.5770088  0.5770088  0.83441526 0.5120114  0.3878629\n",
      " 0.7619662  0.40177742 0.5770088  0.72711235 0.5804823  0.5770088\n",
      " 0.5804823  0.6309701  0.40177742 0.5120114  0.72711235 0.5770088\n",
      " 0.1569075  0.7619662  0.266403   0.5804823  0.585047   0.45087573\n",
      " 0.72711235 0.9181205  0.11454616 0.5770088  0.5120114  0.8396071 ]\n",
      "[0.3878629  0.5770088  0.5804823  0.5804823  0.7619662  0.45087573\n",
      " 0.5770088  0.7619662  0.9209365  0.5120114  0.5770088  0.3878629\n",
      " 0.5120114  0.6217818  0.5804823  0.3878629  0.45087573 0.45087573\n",
      " 0.3878629  0.9234296  0.5120114  0.5770088  0.45087573 0.45087573\n",
      " 0.8396071  0.5725968  0.25058413 0.83441526 0.9209365  0.9640743\n",
      " 0.5770088  0.2652386  0.9234296  0.7001236  0.9234296  0.45087573\n",
      " 0.7619662  0.40177742 0.5194771  0.5770088  0.5804823  0.5725968\n",
      " 0.7619662  0.5770088  0.5770088  0.83441526 0.5120114  0.3878629\n",
      " 0.7619662  0.40177742 0.5770088  0.72711235 0.5804823  0.5770088\n",
      " 0.5804823  0.6309701  0.40177742 0.5120114  0.72711235 0.5770088\n",
      " 0.1569075  0.7619662  0.266403   0.5804823  0.585047   0.45087573\n",
      " 0.72711235 0.9181205  0.11454616 0.5770088  0.5120114  0.8396071 ]\n",
      "0  :  0.3878629\n",
      "1  :  0.5770088\n",
      "0  :  0.5804823\n",
      "1  :  0.5804823\n",
      "0  :  0.7619662\n",
      "1  :  0.45087573\n",
      "1  :  0.5770088\n",
      "1  :  0.7619662\n",
      "0  :  0.9209365\n",
      "0  :  0.5120114\n",
      "1  :  0.5770088\n",
      "0  :  0.3878629\n",
      "0  :  0.5120114\n",
      "1  :  0.6217818\n",
      "0  :  0.5804823\n",
      "1  :  0.3878629\n",
      "0  :  0.45087573\n",
      "1  :  0.45087573\n",
      "1  :  0.3878629\n",
      "1  :  0.9234296\n",
      "1  :  0.5120114\n",
      "1  :  0.5770088\n",
      "1  :  0.45087573\n",
      "0  :  0.45087573\n",
      "1  :  0.8396071\n",
      "1  :  0.5725968\n",
      "0  :  0.25058413\n",
      "1  :  0.83441526\n",
      "0  :  0.9209365\n",
      "0  :  0.9640743\n",
      "0  :  0.5770088\n",
      "1  :  0.2652386\n",
      "0  :  0.9234296\n",
      "1  :  0.7001236\n",
      "1  :  0.9234296\n",
      "1  :  0.45087573\n",
      "0  :  0.7619662\n",
      "0  :  0.40177742\n",
      "1  :  0.5194771\n",
      "0  :  0.5770088\n",
      "1  :  0.5804823\n",
      "1  :  0.5725968\n",
      "1  :  0.7619662\n",
      "1  :  0.5770088\n",
      "0  :  0.5770088\n",
      "0  :  0.83441526\n",
      "1  :  0.5120114\n",
      "0  :  0.3878629\n",
      "0  :  0.7619662\n",
      "1  :  0.40177742\n",
      "1  :  0.5770088\n",
      "0  :  0.72711235\n",
      "1  :  0.5804823\n",
      "0  :  0.5770088\n",
      "1  :  0.5804823\n",
      "0  :  0.6309701\n",
      "1  :  0.40177742\n",
      "0  :  0.5120114\n",
      "1  :  0.72711235\n",
      "1  :  0.5770088\n",
      "0  :  0.1569075\n",
      "0  :  0.7619662\n",
      "1  :  0.266403\n",
      "0  :  0.5804823\n",
      "1  :  0.585047\n",
      "1  :  0.45087573\n",
      "0  :  0.72711235\n",
      "1  :  0.9181205\n",
      "1  :  0.114546165\n",
      "1  :  0.5770088\n",
      "1  :  0.5120114\n",
      "0  :  0.8396071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load the models\n",
    "# bst2 = xgb.Booster(model_file='dump.raw.txt')\n",
    "bst3 = xgb.Booster(model_file='dump.raw.model')\n",
    "\n",
    "#load the test data\n",
    "load_test = xgb.DMatrix('dtest.buffer')\n",
    "\n",
    "load_model_pred = bst3.predict(load_test)\n",
    "\n",
    "\n",
    "# assert np.sum(np.abs(load_model_pred - y_final)) == 0\n",
    "print(np.sum(np.abs(load_model_pred - y_final)) == 0)\n",
    "\n",
    "print(load_model_pred)\n",
    "print(y_final)\n",
    "# dtest.save_binary('dtest.buffer')\n",
    "# # save model\n",
    "# bst.save_model('xgb.model')\n",
    "# # load model and data in\n",
    "# bst2 = xgb.Booster(model_file='xgb.model')\n",
    "# dtest2 = xgb.DMatrix('dtest.buffer')\n",
    "# preds2 = bst2.predict(dtest2)\n",
    "# # assert they are the same\n",
    "# assert np.sum(np.abs(preds2 - preds)) == 0\n",
    "\n",
    "for x, y in zip(test_d['Label'], y_final):\n",
    "    print(x, \" : \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c83341f850>"
      ]
     },
     "execution_count": 1977,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter( test_d['Label'],y_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All scores are printed out for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model 0.5443037974683544\n",
      "Random Forest 0.5738396624472574\n",
      "Sentiment Accuracy 0.5189873417721519\n",
      "Sentiment Accuracy with Trends 0.45569620253164556\n",
      "Weighted Accuracy (Vans) 0.5189873417721519\n",
      "Sentiment Accuracy with Trend with weight (Erika) 0.45569620253164556\n",
      "Weighted accuracy (Vans) attempt 2 0.5569620253164557\n",
      "Sentiment Accuracy (separate models) 0.5138888888888888\n"
     ]
    }
   ],
   "source": [
    "print(\"Base model\", accuracy1)\n",
    "print(\"Random Forest\", accuracyrf)\n",
    "print(\"Sentiment Accuracy\", accuracy_score(test_news['Label'], y_pred))\n",
    "print(\"Sentiment Accuracy with Trends\", accuracy_score(test_news['Label'], y_pred2))\n",
    "print(\"Weighted Accuracy (Vans)\", accuracy_score(test_news['Label'], y_pred_weight))\n",
    "print(\"Sentiment Accuracy with Trend with weight (Erika)\", accuracy_score(test_news['Label'], y_pred4))\n",
    "print(\"Weighted accuracy (Vans) attempt 2\", accuracy_score(test_news['Label'], y_pred_weight1))\n",
    "print(\"Sentiment Accuracy (separate models)\", accuracy_score(test_d['Label'], y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
